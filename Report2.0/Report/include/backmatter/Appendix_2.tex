\chapter{Non-interactive Bulletproofs}
%\label{appendix:VHASS-LSS}
\label{Appendix:Bulletproof}

\begin{algorithm}[]
\caption{\textbf{: Bulletproof}}
\textbf{Goal:}  Given a Pedersen commitment $C=g^x h^R$ and a number $n$, prove that the secret $x$ in the commitment belongs to the range  $[0,2^n)$ without revealing anything else about $x$.
\vspace{2pt}
\hline
\vspace{2pt}
\begin{itemize}
\item\text{\textbf{Prove} $(g,h,\mathbf{g},\mathbf{h},P,n,x,R,u)\xrightarrow[]{}\textit{ proof}_{RP}$}\\
Let $\bm{x}$ denote the binary representation of the secret $x$ in the commitment $C$ and $\bar{\bm{x}}$ the component-wise complement such  that $\bm{x}\circ \bar{\bm{x}} = 0$. Construct the commitment $A= h^{\alpha} \bm{g}^{ \bm{x} } \bm{h}^{ \bar{\bm{x}} }$, where $\alpha \in_R \mathds{F}$. Then chose the two blinding vectors $\bm{s_R},\bm{s_L}\in_R\mathds{F}^n$ and the value $\rho\in_R\mathds{F}$ and compute the commitment $S=h^{\rho} \bm{g}^{\bm{s_L}} \bm{h}^{\bm{s_R}}$. Let $y=\text{Hash}(A,S)$, $z=\text{Hash}(A,S,y)$ and $\tau_1,\tau_2\in_R\mathds{F}$. Now the it is possible to construct $t_1,t_2$ defined above. Given this let $T_1=g^{t_1}h^{\tau_1}$ and $T_2=g^{t_2}h^{\tau_2}$, next let $X=\text{Hash}(T_1,T_2)$. Now construct the two vectors for the inner product argument: $\bm{l} = \bm{x}-z\cdot \bm{1}^n-\bm{s_L}\cdot X$, $\bm{r}= \bm{y}^n\circ(\bar{\bm{x}}+ z\cdot \bm{1}^n+\bm{s_R}\cdot X ) + z^2\ X $ and calculate the inner product $\hat{t} = \langle \bm{l},\bm{r}\rangle$. Finally compute $\tau_X = \tau_2 x^2 + \tau_1 X + z^2 R$ and $\mu = \alpha+ R\:X$.  Now use the inner product argument to prove that $\hat{t}$ is indeed the inner product of the two vectors $\mathbf{l},\mathbf{r}$ using the commitment $P_v = \bm{g}^{\bm{l}}\bm{h}^{\bm{r}}$, run the algorithm  \textbf{Prove}  defined Construction \ref{alg:inner_product} with the input $(\bm{g},\bm{h},u,P_v,\hat{t},\bm{l},\bm{r})$ to construct such a proof denoted  \textit{proof$_{IP}$}. Combine and publish  the proof: $\textit{proof}_{RP} = (\tau_X, \mu , \hat{t}, P, A, S, T_1, T_2 , P_v ,\textit{proof}_{IP}) $.

\item\text{\textbf{Verify} $(g,h,C,\textit{proof}_{RP})\xrightarrow[]{}\{0,1\}$}\\
Compute the three hash functions $y= \text{Hash}(A,S)$, $z= \text{Hash}(A,S,y)$ and $X= \text{Hash}(T_1,T_2)$. Then given  $y,z,X$ compute $h_i' = h_i ^{y^{-i+1}}$ for all $i\in\{1,...,n\}$, $P_l = P\cdot h\mu$ and $P_r = A\cdot S ^x \bm{g}^ {-z}\bm{h'}^{z\bm{y}^n+z^2\cdot \bm{2}^n}$. Then check if the following equalities hold: $P_l\overset{?}{=} P_r \wedge g^{\hat{t}}h^{\tau_X} \overset{?}{=}  P ^{z^2}\:g^{\delta(y,z)}\:T_1^x\:T_2^{x^2}$ and if the output of \textbf{Verify} in Construction \ref{alg:inner_product} on the input $(\text{proof}_{IP})$ is $1$. If all three criterion is fulfilled then the secret  $x$ in the commitment $P$ is in the range $[0,2^n]$.
\end{itemize}
\label{alg:bullet}
\end{algorithm}


\begin{algorithm}
\caption{\textbf{: Inner-product argument}}
\textbf{Goal:} Given a Pedersen vector  commitment $P_v=\bm{g}^{\bm{s}} \bm{h}^{\bm{q}}$ and a value $c$ prove that the two vectors $\bm{s},\bm{q}$ satisfies $\langle\bm{s},\bm{q}\rangle=c$.
\vspace{2pt}
\hline
\vspace{2pt}
\begin{itemize}
\item\text{\textbf{Prove} $(\mathbf{g},\mathbf{h},u,P_v,c,\mathbf{s},\mathbf{q})\xrightarrow[]{}\textit{proof}_{IP}$}\\
Let $y=\text{Hash}_{IP}(\mathbf{g},\mathbf{h},P_v,c) \in\mathds{F}^*$ and compute $P_v'= u^{y\cdot c}P$. Let $\mathbf{l},\mathbf{r}$ be two empty vectors. Run the recursive algorithm \textbf{GenerateProof}$(\mathbf{g},\mathbf{h},u^{x\cdot c},P_v,c,\mathbf{s},\mathbf{q},\mathbf{l},\mathbf{r})$ use the output $(g',h',u',P_v',s',q',\mathbf{l},\mathbf{r})$ to construct the inner product proof $\text{proof}_{IP} =(\mathbf{g},\mathbf{h},u',P_v,s',q',\mathbf{l},\mathbf{r} )$ and output $\textit{proof}_{IP}$. 
\item\text{\textbf{GenerateProof}$(\mathbf{g},\mathbf{h},u,P_v,\mathbf{s},\mathbf{q},\mathbf{l},\mathbf{r}) \xrightarrow[]{}  (g,h,u,P_v,s,q,\mathbf{l},\mathbf{r})$}
\begin{itemize}
    \item If the dimension of the vectors $\mathbf{g},\mathbf{h},\mathbf{s},\mathbf{q}$  drop the bold font and publish the proof $\textit{ proof}_{IP}=(g,h,P_v,u,s,q,\mathbf{l},\mathbf{r})$.
    \item  Otherwise:  Let $n'=n/2$ and define  $c_L=\langle \bm{s}_{[:,n']},\bm{q}_{[n',:]} \rangle$ and $c_R=\langle \mathbf{s}_{[n',:]},\mathbf{q}_{[:,n']} \rangle$. Then use these variables to calculate $L=\mathbf{g}_{[n':]}^{\mathbf{s}_{[:n']}} \mathbf{h}_{[:n']}^{\mathbf{q}_{[n':]}} u^{c_L}$ and $R=\mathbf{g}_{[:n']}^{\mathbf{s}_{[n':]}} \mathbf{h}_{[n':]}^{\mathbf{q}_{[:n']}} u^{c_R}$. Append  $L,R\in\mathds{G}$ to the vectors $\mathbf{l}$ resp $\mathbf{r}$. Now update $y=\text{Hash}_{BP}(L,R)$, and update $\mathbf{g}' = \mathbf{g}_{[:n']}^{y^{-1}}\mathbf{g}_{[n':]}^{y}$, $\mathbf{h}' = \mathbf{h}_{[:n']}^{y}\mathbf{h}_{[n':]}^{y^{-1}}$ and the commitment $P_v'=L^{y^2}PR^{y^{-2}}$. Finally update the vectors $\mathbf{s},\mathbf{q}$ to $\mathbf{s}' = \mathbf{s}_{[:n']}y+\mathbf{s}_{[n':]}y^{-1}$ and $\mathbf{q}' = \mathbf{q}_{[:n']}y^{-1}+\mathbf{q}_{[n':]}y$. Run the algorithm recursively, \textbf{GenerateProof}$(\mathbf{g}',\mathbf{h}',u,P_v',\mathbf{s}',\mathbf{q}',\mathbf{l},\mathbf{r})$ with the updated variables. Note that the vectors $\mathbf{g},\mathbf{h},\mathbf{s},\mathbf{q}$ now have the dimension $n'=n/2$, hence performing the recursion until one-dimensional vectors will require $log\:n$ iterations.
\end{itemize}
\item\text{\textbf{Verify} $(\textit{proof}_{IP} = (\mathbf{g},\mathbf{h},u,P_v,s,q,\mathbf{l},\mathbf{r}))\xrightarrow[]{}\{0,1\}$}\\
For $i\in\{0,log(n)\}$ put $n=n/2$ and $y=\text{Hash}(\bm{l}[i],\bm{r}[i])$, then update the vectors $\bm{g}$ and $\bm{h}$ as well as the  variable $P_v'$ according to, $\bm{g}'= \bm{g}_{[:,n]}^{y^{-1}} \bm{g}_{[n,:]}^{'y}$, $\bm{h}= \bm{h}_l{[:,n]}^{x}\bm{h}_{[n,:]}^{y^{-1}}$ and $ P_v' = L^{y^2}PR^{y^{-2}}  $. After iterating over all $i$ the dimension of the vectors $\bm{g},\bm{h}$ is one and the bold font can be dropped. Compute  $c=\langle s, q\rangle$ and  accept if $P_v' =g^sh^ru^c$.
\end{itemize}
\label{alg:inner_product}
\end{algorithm}

\begin{comment}
\begin{algorithm}
\caption{\textbf{: Verifiable additive homomorphic secret sharing}}
\textbf{Goal:} Construct and share the sum $\sum_{i=1}^n x_i$, where $x_i$ is a secret value known by client $c_i$, where $i\in\mathcal{N}$ without any client needing to revealing their individual secret. The servers, used to sharing the secrets, computations are verified so they must be honest. 
\vspace{2pt}
\hline
\vspace{2pt}
\begin{itemize}
    \item\textbf{SetUp $1^\lambda, N$}
    Let $N$ be the product of two safe primes ($p,q$)  each of length $k'/2$. Choose at random two random safe primes $\hat{p},\hat{q}$ of length $k/2$, such that $\text{gcd}(N,\Phi(\hat{N}))=1$, where $\hat{N}=\hat{p}\hat{q}$. Then choose $g,g_1,g_2,h_1,...,h_n$ in $\mathds{Z}_{\hat{N}}$ at random. Choose an (efficiently computational) injective function $H:\{0,1\}^* \mapsto \{0,1\}^l$, with $l<k'/2$. Define the public verification key $vk= (N,H,\hat{N},g,g_1,g_2,h_1,...,h_n)$ and the private signing key to $sk=(\hat{p},\hat{q})$. 
  \item\textbf{ShareSecret $(1^\lambda,i,x_i)\xrightarrow[]{}(\{x_{ij}\}_{j\in\mathcal{M}})$}\\
Pick uniformly at random $\{a_i\}_{i\in\{1,..,t\}}\in\mathds{F}$ and a $t$-degree, put $x_{ij}=\lambda_{i,j}p_i(\theta_{ij})$.  Output $x_{i,j}$ for $j\in\mathcal{M}$. 

%, be a collision-resistant homomorphic hash function. Let $R_i\in\mathds{F}$ be the output of a PRF.$R_n = \phi(N)\lceil \frac{\sum_{i=1}^{n-1}R_i}{\phi(N)}\rceil- \sum_{i=1}^{n-1}R_i $. Compute $\tau_i = \mathcal{H}(x_i+R_i)$, 

\item\textbf{PartialEval $(j,\{x_{ij}\}_{i\in\mathcal{N}})\xrightarrow[]{}y_j$}\\
Compute and output $y_j = \sum_{i=1}^n x_{ij}$.

\item\textbf{PartialProof $(sk,vk,fid,x_i,i)\xrightarrow[]{}\sigma_j$}\\
Parse the verification key $vk$. Use the injective function $H$ to compute the prime $e=H(fid)$. Let $R_i\in\mathds{F}$ be the output of a PRF. $R_n, = \phi(N)\lceil \frac{\sum_{i=1}^{n-1}R_i}{\phi(N)}\rceil- \sum_{i=1}^{n-1}R_i $.  Choose at random $s_i\in_R\mathds{Z}_\hat{N}$ and use the secret key $sk$ to solve for $x$ in the equation $x^{eN}= g^{sj}\prod_{j=1}^n h_j^{f_j^{(i)}}g_1^{x_i+R_i} \: \text{mod}(\hat{N})$. Let the vector $f^{(i)}$ be the canonical bases $e_i$ of $\mathds{Z}^n$, this reduced the equation to $x^{eN}= g^{s_j} h_i g_1^{x_i+R_i} \: \text{mod}(\hat{N})$, set $\tilde{x}_i=x$ 
and output the partial proof $\sigma_i= (e,s_i,fid,\tilde{x}_i)$.

\item\textbf{ConstructRangeProof $x_i,i \mapsto proof_{RP}$}\\
Let $r_i\in\mathds{F}$ be the output of a PRF. $r_n, = \phi(N)\lceil \frac{\sum_{i=1}^{n-1}r_i}{\phi(N)}\rceil- \sum_{i=1}^{n-1}r_i $ and compute the Fujisaki-Okamoto commitment $\pi_i=g_1^{x_i}g_2^{r_i}$.
Use the commitment $\pi_i$ to construct a square-based range proof for the secret $x_i$ denoted $proof_{RP}$. Output $(\pi_i,proof_{RP_i})$.
 
\item\textbf{FinalEval $(\{y_j\}_{j\in\mathcal{M}})\xrightarrow[]{}y$}\\
Compute and output $y = \sum_{j=1}^m y_{j}$.

\item\textbf{FinalProof $(vk,\sigma_1,...,\sigma_n)\xrightarrow[]{}\sigma$}\\
Parse the partial proofs $\sigma_i$ to get $(e,s_i,fid,\tilde{x}_i,\pi_i)$.  
Let $\hat{f}= (\alpha_1,...,\alpha_n)\in\mathds{Z}^n$ and define $f' = ( \sum_{i=1}^n \alpha_if^(i)-f)/(eN)$, where $f=\sum_{i=1}^n\alpha f^{(i)} \: \text{mod}\:eN$. Set $s= \sum_{i=1}^n\alpha_is_i \: \text{mod}\:eN$, $s' = (\sum_{i=1}^n \alpha_i s_i -s)/eN \: \text{mod}\: eN$ and $\tilde{x} = \frac{\prod_{i=1}^n \tilde{x}_i^{\alpha_i}}{g^{s'}\prod_{j=1}^n h_j ^{f'}} \: \text{mod}\: \hat{N}$. Let $\alpha_i =1 \: \forall i\in\{1,...,n\}$, then compute  $\tilde{x} = \frac{\prod_{i=1}^n \tilde{x}_i}{g^{s'}\prod_{j=1}^n h_j ^{f'}} \: \text{mod}\: \hat{N}$.

Output the final proof $\sigma = (e,s,fid,\tilde{x})$.

\item\textbf{Verify $(vk,f,\sigma,y,\pi_i,...,\pi_n,proof_{RP_1},...,proof_{RP_n})\xrightarrow[]{}\{0,1\}$}\\
Compute $e=H(fid)$. Check that $y,s\in\mathds{Z}_\hat{N}$ and $\tilde{x}^{eN} = g^s\prod_{j=1}^n h_j^{f}g_1^y$. Further check that $g_1^y =\prod_{i=1}^n \pi_i$ and \textbf{VerifyRP}$(\pi_i,proof_{RP_i})\: \forall i\in\mathcal{N}$ 
\end{itemize}
\label{alg:VAHSS-LSS}
\end{algorithm}

\section*{Questions}
\begin{itemize}
\item Would it be possible to let $x$ be the solution to $x^{eN} = g^{s_j}h_ig_1^{x_i}g_2^{R_i} =  g^{s_j}h_i\pi_i $
\end{itemize}
\section*{Correctness, Securist and Verifiability}
\begin{itemize}
    \item \textbf{Correctness} Need to show $\text{Pr}[\textbf{Verify}(vk,f,\sigma,y\pi_1,...,\pi_n,proof_{RP_1},...,proof_{RP_n}) = 1] = 1$. For this it requires to show that all three following holds at the same time
    \begin{enumerate}
        \item $\tilde{x}^{eN} \overset{?}{=} g^s (\prod_{i=1}^n h_i^f )g_1^y$ \quad \quad (\textit{Holds given that} $y=\sum_{i=1}^n x_i$ ) 
        \item $g_1^y \overset{?}{=} \prod_{i=1}^n \pi_i$ \quad \quad (\textit{Holds given that $x_i=\sum_{j=1}^m x_{ij}$ and $\pi_i = g_1^{\hat{x}_i}g_2^{r_i}$ such that $x_i = \hat{x}_i$} ) 
        \item $\textbf{VerifyRP}(\pi_i,proof_{RP_i})\overset{?}{=}1 \: \forall i\in\mathcal{N}$ (\textit{Holds given that $x_i\in [a,b]\: \forall i\in\mathcal{N}$} ) 
    \end{enumerate}  
    The first statement is proved to hold by original VAHSS-LHS. For the seconds statment it holds that;
    \begin{align*}
        LHS = g_1^y = g_1^{\sum_{j=1}^m y_{j}} \overset{*}{=} g_1^{\sum_{j=1}^m \sum_{i=1}^n x_{ij}}
 = g_1^{\sum_{i=1}^n x_{i}} \text{ *Due to first statement.} \\
 RHS = \prod_{i=1}^n \pi_i = \prod_{i=1}^n g_1^{x_i}g_2^{r_i} = g_1^{\sum_{i=1}^n x_i} g_2 ^{\sum_{i=1}^n r_i} =  g_1^{\sum_{i=1}^n x_i}.  \implies LHS = RHS
 \end{align*} 
 
 The last follows from the verification of a correctly constructed range proof.
 
 \item\textbf{Security} 
 
 \item \textbf{Verifiability}
    \begin{itemize}
        \item If $x_i=\sum_{j=1}^m x_{ij}$,  $\pi_i = g_1^{\hat{x}_i}g_2^{r_i}$  and  $x_i \neq \hat{x}_i$, then,
        \begin{align*}
            g_1^y = \prod_{i=1}^n \pi_i \implies
            g^{\sum_{i=1}^n x_{i}} =  g^{\sum_{i=1}^n \hat{x}_{i}} \implies \\
            \sum_{i=1}^n x_{i} = \sum_{i=1}^n \hat{x}_{i} \text{ (Contraction)}
        \end{align*}
    \end{itemize}
\end{itemize}
\end{comment}